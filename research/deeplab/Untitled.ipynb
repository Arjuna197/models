{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deeplab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4f161795d0cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcommon\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google Drive\\CS\\deeplab\\model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \"\"\"\n\u001b[0;32m     54\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdeeplab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mslim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'deeplab'"
     ]
    }
   ],
   "source": [
    "# Copyright 2018 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Tests for DeepLab model and some helper functions.\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import common\n",
    "import model\n",
    "\n",
    "\n",
    "class DeeplabModelTest(tf.test.TestCase):\n",
    "\n",
    "  def testScaleDimensionOutput(self):\n",
    "    self.assertEqual(161, model.scale_dimension(321, 0.5))\n",
    "    self.assertEqual(193, model.scale_dimension(321, 0.6))\n",
    "    self.assertEqual(241, model.scale_dimension(321, 0.75))\n",
    "\n",
    "  def testWrongDeepLabVariant(self):\n",
    "    model_options = common.ModelOptions([])._replace(\n",
    "        model_variant='no_such_variant')\n",
    "    with self.assertRaises(ValueError):\n",
    "      model._get_logits(images=[], model_options=model_options)\n",
    "\n",
    "  def testBuildDeepLabv2(self):\n",
    "    batch_size = 2\n",
    "    crop_size = [41, 41]\n",
    "\n",
    "    # Test with two image_pyramids.\n",
    "    image_pyramids = [[1], [0.5, 1]]\n",
    "\n",
    "    # Test two model variants.\n",
    "    model_variants = ['xception_65']\n",
    "\n",
    "    # Test with two output_types.\n",
    "    outputs_to_num_classes = {'semantic': 3,\n",
    "                              'direction': 2}\n",
    "\n",
    "    expected_endpoints = [['merged_logits'],\n",
    "                          ['merged_logits',\n",
    "                           'logits_0.50',\n",
    "                           'logits_1.00']]\n",
    "    expected_num_logits = [1, 3]\n",
    "\n",
    "    for model_variant in model_variants:\n",
    "      model_options = common.ModelOptions(outputs_to_num_classes)._replace(\n",
    "          add_image_level_feature=False,\n",
    "          aspp_with_batch_norm=False,\n",
    "          aspp_with_separable_conv=False,\n",
    "          model_variant=model_variant)\n",
    "\n",
    "      for i, image_pyramid in enumerate(image_pyramids):\n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "          with self.test_session(graph=g):\n",
    "            inputs = tf.random_uniform(\n",
    "                (batch_size, crop_size[0], crop_size[1], 3))\n",
    "            outputs_to_scales_to_logits = model.multi_scale_logits(\n",
    "                inputs, model_options, image_pyramid=image_pyramid)\n",
    "\n",
    "            # Check computed results for each output type.\n",
    "            for output in outputs_to_num_classes:\n",
    "              scales_to_logits = outputs_to_scales_to_logits[output]\n",
    "              self.assertListEqual(sorted(scales_to_logits.keys()),\n",
    "                                   sorted(expected_endpoints[i]))\n",
    "\n",
    "              # Expected number of logits = len(image_pyramid) + 1, since the\n",
    "              # last logits is merged from all the scales.\n",
    "              self.assertEquals(len(scales_to_logits), expected_num_logits[i])\n",
    "\n",
    "  def testForwardpassDeepLabv3plus(self):\n",
    "    crop_size = [33, 33]\n",
    "    outputs_to_num_classes = {'semantic': 3}\n",
    "\n",
    "    model_options = common.ModelOptions(\n",
    "        outputs_to_num_classes,\n",
    "        crop_size,\n",
    "        atrous_rates=[6],\n",
    "        output_stride=16\n",
    "    )._replace(\n",
    "        add_image_level_feature=True,\n",
    "        aspp_with_batch_norm=True,\n",
    "        aspp_with_separable_conv=True,\n",
    "        decoder_output_stride=4,\n",
    "        decoder_use_separable_conv=True,\n",
    "        logits_kernel_size=1,\n",
    "        model_variant='xception_65')\n",
    "\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "      with self.test_session(graph=g) as sess:\n",
    "        inputs = tf.random_uniform(\n",
    "            (1, crop_size[0], crop_size[1], 3))\n",
    "        outputs_to_scales_to_logits = model.multi_scale_logits(\n",
    "            inputs,\n",
    "            model_options,\n",
    "            image_pyramid=[1.0])\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        outputs_to_scales_to_logits = sess.run(outputs_to_scales_to_logits)\n",
    "\n",
    "        # Check computed results for each output type.\n",
    "        for output in outputs_to_num_classes:\n",
    "          scales_to_logits = outputs_to_scales_to_logits[output]\n",
    "          # Expect only one output.\n",
    "          self.assertEquals(len(scales_to_logits), 1)\n",
    "          for logits in scales_to_logits.values():\n",
    "            self.assertTrue(logits.any())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.test.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"path/to/Modules\")\n",
    "print sys.path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
